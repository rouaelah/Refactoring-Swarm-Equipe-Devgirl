#!/usr/bin/env python3
import argparse
import sys
import os
from pathlib import Path
from dotenv import load_dotenv

# 1. Chargement de l'environnement
load_dotenv()

# V√©rification imp√©rative de la cl√©
if not os.getenv("GOOGLE_API_KEY"):
    print("‚ùå ERREUR: GOOGLE_API_KEY manquante dans le fichier .env")
    sys.exit(1)

# Ajout du chemin src pour les imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.agents.auditor import AuditorAgent
from src.agents.fixer import FixerAgent
from src.agents.judge import JudgeAgent
from src.tools.llm_client import get_llm_client

def main():
    parser = argparse.ArgumentParser(description="Refactoring Swarm - Orchestrator")
    
    parser.add_argument("--target_dir", required=True, help="Dossier contenant le code √† refactoriser")
    parser.add_argument("--max_iterations", type=int, default=10, help="Limite d'auto-gu√©rison (max 10)")
    parser.add_argument("--model", default="gemini-1.5-flash", help="Mod√®le Gemini officiel")
    parser.add_argument("--verbose", action="store_true", help="Mode d√©taill√©")

    args = parser.parse_args()
    target_path = Path(args.target_dir).resolve()

    # --- INITIALISATION ---
    print(f"ü§ñ Initialisation du syst√®me avec le mod√®le: {args.model}")
    try:
        # On passe verbose pour voir les logs si besoin
        llm_client = get_llm_client(model_name=args.model, temperature=0.1)
    except Exception as e:
        print(f"‚ùå Erreur client LLM: {e}")
        sys.exit(1)

    auditor = AuditorAgent(llm_client)
    fixer = FixerAgent(llm_client)
    judge = JudgeAgent(llm_client)

    # --- ETAPE 1: AUDIT ---
    print(f"\nüîç √âTAPE 1: ANALYSE INITIALE DU CODE DANS {target_path}")
    analysis_results = auditor.analyze_codebase(str(target_path))
    
    if not analysis_results:
        print("‚ö†Ô∏è Aucun fichier Python d√©tect√© ou erreur d'analyse.")
        sys.exit(1)

    # --- ETAPE 2: BOUCLE DE SELF-HEALING ---
    print("\nüîß √âTAPE 2: BOUCLE DE CORRECTION ET TESTS")
    iteration = 1
    success = False
    feedback_erreurs = None

    

    while iteration <= args.max_iterations and not success:
        print(f"\n--- üîÑ It√©ration {iteration}/{args.max_iterations} ---")
        
        # A. Correction de chaque fichier audit√©
        for plan in analysis_results:
            # Extraction s√©curis√©e du chemin
            file_path = plan.get("file_path")
            if not file_path:
                continue
                
            print(f"üõ†Ô∏è Fixer: Travail sur {file_path}...")
            fixer.fix_file(file_path, str(plan), feedback_erreurs)

        # B. Test et Jugement global du dossier
        print("üß™ Judge: Lancement de la suite de tests...")
        success, test_results = judge.run_tests(str(target_path))

        if success:
            print("‚úÖ SUCC√àS: Tous les tests passent !")
            # Validation bonus de l'am√©lioration
            for plan in analysis_results:
                f_path = plan.get("file_path")
                old_s = plan.get("pylint_score", 0.0)
                if f_path:
                    judge.validate_improvement(f_path, old_s)
            break
        else:
            print("‚ùå √âCHEC: Des tests ne passent pas encore.")
            feedback_erreurs = judge.generate_failure_report(test_results)
            iteration += 1
            if iteration <= args.max_iterations:
                print(f"üîÅ Nouvelle tentative de correction bas√©e sur les erreurs de test...")

    # --- ETAPE 3: RAPPORT FINAL ---
    print("\n" + "="*50)
    if success:
        print("üéâ MISSION R√âUSSIE : Code propre et valid√©.")
    else:
        print("üõë √âCHEC : Limite d'it√©rations atteinte sans succ√®s complet.")
    
    print(f"üìä Logs disponibles dans: logs/experiment_data.json")
    print("="*50)

if __name__ == "__main__":
    main()